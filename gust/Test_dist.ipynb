{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gust\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from numpy import matrix\n",
    "import scipy\n",
    "import scipy.sparse as sp\n",
    "import torch.distributions as dist\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4b935b619275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the dataset using `gust` library\n",
    "# graph.standardize() makes the graph unweighted, undirected and selects\n",
    "# the largest connected component\n",
    "# graph.unpack() returns the necessary vectors / matrices\n",
    "\n",
    "A, X, _, y = gust.load_dataset('cora').standardize().unpack()\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.8, random_state=0)\n",
    "train_index, test_index = sss.split(self, emb, Y, groups=None)\n",
    "train_X = A[train_index]\n",
    "test_X = A[test_index]\n",
    "train_y = y[train_index]\n",
    "test_y = y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "A, X, _, z = gust.load_dataset('cora_ml').standardize().unpack()\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.8, random_state=0)\n",
    "\n",
    "#adj = torch.FloatTensor(A.toarray()).cuda()\n",
    "#A = A[0:4,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def laplacian(A):\n",
    "    #Transition Matrix P=D-A\n",
    "    num_nodes = A.shape[0]\n",
    "    D = np.ravel(A.sum(1))\n",
    "    L = sp.diags(D) - A\n",
    "    return L\n",
    "\n",
    "\n",
    "def sym_normalized_laplacian(A):\n",
    "    #Symmetric, Normalized Laplacian P=D^(−1/2)AD^(−1/2)\n",
    "    num_nodes = A.shape[0]\n",
    "    D = np.ravel(A.sum(1))\n",
    "    #D[D == 0] = 1  # avoid division by 0 error\n",
    "    D_sqrt = np.sqrt(D)\n",
    "    a=np.ones(D_sqrt.shape[0])\n",
    "    D_sqrt_inv = np.divide(a, D_sqrt, out=np.zeros_like(a), where=D!=0) \n",
    "    L = sp.diags(D_sqrt_inv) * A * sp.diags(D_sqrt_inv)\n",
    "    #L = A / D_sqrt[:, None] / D_sqrt[None, :]\n",
    "    return L\n",
    "\n",
    "def Transition(A):\n",
    "    #Laplacian P=D^−1A\n",
    "    num_nodes = A.shape[0]\n",
    "    D = np.ravel(A.sum(1))\n",
    "    #D[D == 0] = 1  # avoid division by 0 error\n",
    "    a=np.ones(D.shape[0])\n",
    "    D_inv = np.divide(a, D, out=np.zeros_like(a), where=D!=0)\n",
    "    L = sp.diags(D_inv) * A\n",
    "    return L\n",
    "\n",
    "def PPR(A):\n",
    "    #Personalized PageRank Matrix as described in https://openreview.net/pdf?id=H1gL-2A9Ym with the there used hyperparameter alpha=0.1\n",
    "    #P=alpha(I-(1-alpha)*D^-1/2(A+I)D^-1/2)^-1\n",
    "    print(A.toarray())\n",
    "    alpha = 0.1  \n",
    "    num_nodes = A.shape[0]\n",
    "    D = np.ravel(A.sum(1))\n",
    "    #D[D == 0] = 1  # avoid division by 0 error\n",
    "    D_sqrt = np.sqrt(D)\n",
    "    a=np.ones(D_sqrt.shape[0])\n",
    "    D_sqrt_inv = np.divide(a, D_sqrt, out=np.zeros_like(a), where=D!=0)\n",
    "    A_tilde = sp.diags(D_sqrt_inv) * (A + sp.identity(A.shape[0])) * sp.diags(D_sqrt_inv)\n",
    "    print('A_tilde: ', A_tilde.toarray())\n",
    "    L_inv = (sp.identity(A.shape[0]) - (1-alpha) * A_tilde)\n",
    "    print('L_inv: ', L_inv.toarray())\n",
    "    L = alpha * np.linalg.pinv(L_inv.toarray())\n",
    "    print(L)\n",
    "    return L\n",
    "\n",
    "def NetMF(A):\n",
    "    eps=1e-5\n",
    "    #volume of the graph, usually for weighted graphs, here weight 1\n",
    "    vol = A.sum()\n",
    "    \n",
    "    #b is the number of negative samples, hyperparameter\n",
    "    b = 3\n",
    "    \n",
    "    #T is the window size, as a small window size algorithm is used, set T=10, which showed the best results in the paper\n",
    "    T=10\n",
    "    \n",
    "    #Transition Matrix P=D^-1A\n",
    "    num_nodes = A.shape[0]\n",
    "    D = np.ravel(A.sum(1))\n",
    "    #D[D == 0] = 1  # avoid division by 0 error\n",
    "    a=np.ones(D.shape[0])\n",
    "    D_inv = np.divide(a, D, out=np.zeros_like(a), where=D!=0)\n",
    "    P = np.diag(D_inv) * A.todense()\n",
    "    \n",
    "    #Compute M = vol(G)/bT (sum_r=1^T P^r)D^-1\n",
    "    sum_np=0\n",
    "    for r in range(1,T+1):\n",
    "        sum_np+=np.linalg.matrix_power(P,r)\n",
    "    M = sum_np * np.diag(D_inv) * vol / (b*T)\n",
    "    M_max = np.maximum(M,np.ones(M.shape[0]))\n",
    "\n",
    "    #Compute SVD of M\n",
    "    u, s, vh = np.linalg.svd(np.log(M_max), full_matrices=True)\n",
    "\n",
    "    #Compute L\n",
    "    L = u*np.diag(np.sqrt(s+eps))\n",
    "    print(L.sum(axis=1))\n",
    "    return L\n",
    "\n",
    "def simrank_quick(A, C = 0.8, acc = 0.1):\n",
    "    #https://link.springer.com/chapter/10.1007/978-3-642-14246-8_29\n",
    "    #Algorithm 2: PAUG-SimRank: Parallel Accelerative SimRank for Undirected Graphs\n",
    "    #Step 1: Spectral Predecomposition\n",
    "    A = A.todense()\n",
    "    print(torch.tensor(A))\n",
    "    eigvalues, eigvectors = torch.eig(torch.tensor(A), eigenvectors=True)\n",
    "    eigvalues = eigvalues[:,0]\n",
    "    \n",
    "    #Step 2: Iterative Elementwise Matrix Multiplication\n",
    "    #for i in range(eigvalues.shape[0]):\n",
    "        \n",
    "        \n",
    "    \n",
    "    return \n",
    "\n",
    "def simrank(A, C = 0.8, acc = 1e-10):\n",
    "    #https://link.springer.com/chapter/10.1007/978-3-642-14246-8_29\n",
    "    #Algorithm 1: AUG-SimRank: Accelerative SimRank for Undirected Graphs\n",
    "    A_torch = torch.tensor(A.todense())\n",
    "    \n",
    "    #Calculate Transition Probability Q\n",
    "    Q_torch = A_torch / A_torch.sum(1, keepdims=True)\n",
    "    Q = np.squeeze(np.asarray((A / np.sum(A,axis = 1))))\n",
    "    \n",
    "    \n",
    "    #Decompose Q\n",
    "    eigvalues_t, eigvectors_t = torch.eig(Q_torch, eigenvectors=True)\n",
    "    eigvalues_np, eigvectors_np = np.linalg.eig(Q)\n",
    "    #for undirected graphs all eigenvalues are real\n",
    "    eigvectors_np=np.real(eigvectors_np)\n",
    "    eigvalues_np=np.real(eigvalues_np)\n",
    "    \n",
    "    eigvalues_t_real = eigvalues_t[:,0]\n",
    "\n",
    "    #Initialize\n",
    "    #S_old = torch.eye(Q.shape[0])\n",
    "    S_old_np = np.identity(Q.shape[0])\n",
    "    S_old_t = torch.eye(Q_torch.shape[0])\n",
    "    M_np = C * np.diag(eigvalues_np) @ np.transpose(np.diag(eigvalues_np))  \n",
    "    M_t = C * torch.diag(eigvalues_t_real) @ torch.diag(eigvalues_t_real).T\n",
    " \n",
    "    #Converge\n",
    "    while True:\n",
    "        S_new_np = np.maximum(np.multiply(M_np, S_old_np), np.identity(M_np.shape[0]))\n",
    "        \n",
    "        if (np.absolute(S_new_np-S_old_np)).max()<acc:\n",
    "            break\n",
    "        S_old_np = S_new_np\n",
    "    \n",
    "    #L = eigvectors @ S_new @ np.linalg.inv(eigvectors)\n",
    "    print('S_new_np: ', S_new_np)\n",
    "    L_np = np.dot(eigvectors_np, np.dot(S_new_np, np.linalg.inv(eigvectors_np)))\n",
    "        \n",
    "    #Converge\n",
    "    while True:\n",
    "        S_new_t = torch.max(M_t*S_old_t,torch.eye(M_t.shape[0]))\n",
    "        \n",
    "        if torch.max(torch.abs(S_new_t-S_old_t))<acc:\n",
    "            break\n",
    "        S_old_t = S_new_t\n",
    "    print('S_new_t: ', S_new_t)\n",
    "    L_t = eigvectors_t @ S_new_t @ torch.inverse(eigvectors_t)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    return L_np, L_t\n",
    "\n",
    "\n",
    "L = laplacian(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = A.shape[0]\n",
    "D = 32\n",
    "\n",
    "Z = nn.Parameter(torch.empty(N, D).normal_(std=0.1))\n",
    "x = nn.Parameter(torch.empty(N, D).normal_(std=0.1))\n",
    "\n",
    "opt = torch.optim.Adam([Z], lr=1e-2)\n",
    "e1, e2 = A.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(Z, b=0.1, eps=1e-8): \n",
    "    dist = torch.matmul(Z,Z.T) +b\n",
    "    sigdist = 1/(1+torch.exp(dist+eps)+eps)\n",
    "    logsigdist = torch.log(sigdist+eps)\n",
    "    pos_term = logsigdist[e1,e2]\n",
    "    neg_term = torch.log(1-sigdist)\n",
    "    neg_term[np.diag_indices(N)] = 0.0\n",
    "    \n",
    "    return -(pos_term.sum() + neg_term.sum()) / Z.shape[0]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(Z, eps=1e-5):\n",
    "    gamma = 0.1\n",
    "    dist = ((Z[:, None] - Z[None, :]).pow(2.0).sum(-1) + eps).sqrt()\n",
    "    neg_term = torch.log(-torch.expm1(-dist)*gamma + eps)\n",
    "    neg_term[np.diag_indices(N)] = 0.0\n",
    "    pos_term = -dist[e1, e2]   \n",
    "    neg_term[e1, e2] = 0.0\n",
    "    \n",
    "    return -(pos_term.sum() + neg_term.sum()) / Z.shape[0]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp(Z, eps=1e-8):\n",
    "    #e1, e2 = similarity_measure.nonzero()\n",
    "    emb_abs = torch.FloatTensor.abs(Z)\n",
    "    dist = -torch.matmul(emb_abs, emb_abs.T)\n",
    "    neg_term = dist\n",
    "    neg_term[np.diag_indices(Z.shape[0])] = 0.0\n",
    "    expdist = torch.exp(dist)\n",
    "    embedding = 1 - expdist\n",
    "    logdist = torch.log(embedding + eps)\n",
    "    pos_term = logdist[e1, e2]\n",
    "    size=Z.shape[0]\n",
    "    return -(pos_term.sum() + neg_term.sum()) / Z.shape[0]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl(L, Z, eps=1e-8):\n",
    "    #P=softmax(ZZ^T)\n",
    "    dist=torch.matmul(Z,Z.T)\n",
    "    sigdist = 1/(1+torch.exp(dist+eps)+eps)\n",
    "    logsigdist = torch.log(sigdist+eps)\n",
    "    losses = T*logsigdist\n",
    "    return losses.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9060537815093994\n",
      "2.8549840450286865\n",
      "2.8081750869750977\n",
      "2.765533924102783\n",
      "2.726851224899292\n",
      "2.6918540000915527\n",
      "2.6602418422698975\n",
      "2.631711721420288\n",
      "2.605971336364746\n",
      "2.582746744155884\n",
      "2.561783790588379\n",
      "2.5428497791290283\n",
      "2.5257346630096436\n",
      "2.510248899459839\n",
      "2.496222734451294\n",
      "2.483503818511963\n",
      "2.4719555377960205\n",
      "2.461456537246704\n",
      "2.4518988132476807\n",
      "2.443185567855835\n",
      "2.4352309703826904\n",
      "2.4279584884643555\n",
      "2.421299457550049\n",
      "2.415193796157837\n",
      "2.409585952758789\n",
      "2.404428720474243\n",
      "2.3996782302856445\n",
      "2.3952958583831787\n",
      "2.391246795654297\n",
      "2.387500047683716\n",
      "2.3840279579162598\n",
      "2.380805492401123\n",
      "2.3778109550476074\n",
      "2.3750228881835938\n",
      "2.3724238872528076\n",
      "2.3699984550476074\n",
      "2.3677303791046143\n",
      "2.365607261657715\n",
      "2.363616704940796\n",
      "2.3617475032806396\n",
      "2.3599910736083984\n",
      "2.358337163925171\n",
      "2.356778621673584\n",
      "2.3553075790405273\n",
      "2.3539175987243652\n",
      "2.352602243423462\n",
      "2.351356029510498\n",
      "2.35017466545105\n",
      "2.3490521907806396\n",
      "2.3479855060577393\n",
      "2.3469698429107666\n",
      "2.3460028171539307\n",
      "2.3450798988342285\n",
      "2.3441991806030273\n",
      "2.3433570861816406\n",
      "2.3425512313842773\n",
      "2.341779947280884\n",
      "2.341040849685669\n",
      "2.3403313159942627\n",
      "2.3396503925323486\n",
      "2.338995933532715\n",
      "2.3383662700653076\n",
      "2.3377604484558105\n",
      "2.337177038192749\n",
      "2.336613893508911\n",
      "2.336071014404297\n",
      "2.3355469703674316\n",
      "2.33504056930542\n",
      "2.3345510959625244\n",
      "2.3340775966644287\n",
      "2.3336195945739746\n",
      "2.3331756591796875\n",
      "2.3327460289001465\n",
      "2.3323287963867188\n",
      "2.3319246768951416\n",
      "2.3315324783325195\n",
      "2.3311514854431152\n",
      "2.3307814598083496\n",
      "2.3304214477539062\n",
      "2.3300719261169434\n",
      "2.3297319412231445\n",
      "2.3294010162353516\n",
      "2.3290786743164062\n",
      "2.3287649154663086\n",
      "2.3284595012664795\n",
      "2.3281619548797607\n",
      "2.327871322631836\n",
      "2.3275883197784424\n",
      "2.3273122310638428\n",
      "2.327042818069458\n",
      "2.326780080795288\n",
      "2.3265230655670166\n",
      "2.326272487640381\n",
      "2.3260276317596436\n",
      "2.3257884979248047\n",
      "2.325554847717285\n",
      "2.3253259658813477\n",
      "2.3251025676727295\n",
      "2.3248839378356934\n",
      "2.3246703147888184\n",
      "2.324460983276367\n",
      "2.324256420135498\n",
      "2.3240561485290527\n",
      "2.323859930038452\n",
      "2.3236677646636963\n",
      "2.3234798908233643\n",
      "2.3232953548431396\n",
      "2.323115348815918\n",
      "2.3229379653930664\n",
      "2.3227651119232178\n",
      "2.3225951194763184\n",
      "2.3224284648895264\n",
      "2.322265148162842\n",
      "2.3221046924591064\n",
      "2.3219478130340576\n",
      "2.321793556213379\n",
      "2.3216423988342285\n",
      "2.3214943408966064\n",
      "2.3213489055633545\n",
      "2.3212058544158936\n",
      "2.3210654258728027\n",
      "2.320927619934082\n",
      "2.3207926750183105\n",
      "2.320659875869751\n",
      "2.3205294609069824\n",
      "2.320401668548584\n",
      "2.3202755451202393\n",
      "2.3201518058776855\n",
      "2.320030450820923\n",
      "2.319911241531372\n",
      "2.319793939590454\n",
      "2.319678544998169\n",
      "2.3195652961730957\n",
      "2.319453716278076\n",
      "2.3193442821502686\n",
      "2.3192367553710938\n",
      "2.3191304206848145\n",
      "2.319026470184326\n",
      "2.3189241886138916\n",
      "2.3188233375549316\n",
      "2.3187239170074463\n",
      "2.3186261653900146\n",
      "2.318530321121216\n",
      "2.3184359073638916\n",
      "2.318342924118042\n",
      "2.318251132965088\n",
      "2.3181610107421875\n",
      "2.3180723190307617\n",
      "2.3179852962493896\n",
      "2.317898988723755\n",
      "2.317814588546753\n",
      "2.3177309036254883\n",
      "2.3176488876342773\n",
      "2.317568302154541\n",
      "2.317488431930542\n",
      "2.3174099922180176\n",
      "2.3173327445983887\n",
      "2.317256450653076\n",
      "2.3171818256378174\n",
      "2.317107677459717\n",
      "2.317034959793091\n",
      "2.316962957382202\n",
      "2.316892147064209\n",
      "2.3168222904205322\n",
      "2.316753625869751\n",
      "2.3166861534118652\n",
      "2.3166189193725586\n",
      "2.3165531158447266\n",
      "2.316488027572632\n",
      "2.3164241313934326\n",
      "2.3163609504699707\n",
      "2.316298484802246\n",
      "2.316236972808838\n",
      "2.316176652908325\n",
      "2.3161168098449707\n",
      "2.3160579204559326\n",
      "2.315999746322632\n",
      "2.3159422874450684\n",
      "2.315885543823242\n",
      "2.315829277038574\n",
      "2.315774440765381\n",
      "2.3157200813293457\n",
      "2.3156661987304688\n",
      "2.315613269805908\n",
      "2.315561056137085\n",
      "2.31550931930542\n",
      "2.315458297729492\n",
      "2.3154077529907227\n",
      "2.3153581619262695\n",
      "2.3153090476989746\n",
      "2.315260410308838\n",
      "2.3152127265930176\n",
      "2.3151650428771973\n",
      "2.3151187896728516\n",
      "2.315072536468506\n",
      "2.3150272369384766\n",
      "2.3149819374084473\n",
      "2.3149375915527344\n",
      "2.3148937225341797\n",
      "2.3148505687713623\n",
      "2.314807653427124\n",
      "2.314765453338623\n",
      "2.3147239685058594\n",
      "2.3146822452545166\n",
      "2.3146414756774902\n",
      "2.314600944519043\n",
      "2.314561128616333\n",
      "2.3145222663879395\n",
      "2.3144829273223877\n",
      "2.3144445419311523\n",
      "2.314406633377075\n",
      "2.314368963241577\n",
      "2.3143320083618164\n",
      "2.3142950534820557\n",
      "2.314258575439453\n",
      "2.314222812652588\n",
      "2.3141872882843018\n",
      "2.314152479171753\n",
      "2.314117431640625\n",
      "2.3140833377838135\n",
      "2.314049243927002\n",
      "2.3140156269073486\n",
      "2.3139824867248535\n",
      "2.3139495849609375\n",
      "2.3139171600341797\n",
      "2.31388521194458\n",
      "2.3138532638549805\n",
      "2.31382155418396\n",
      "2.313791036605835\n",
      "2.3137600421905518\n",
      "2.3137295246124268\n",
      "2.313699245452881\n",
      "2.3136696815490723\n",
      "2.3136403560638428\n",
      "2.313610792160034\n",
      "2.313582420349121\n",
      "2.31355357170105\n",
      "2.313525438308716\n",
      "2.313497304916382\n",
      "2.313469886779785\n",
      "2.3134422302246094\n",
      "2.313415050506592\n",
      "2.3133883476257324\n",
      "2.313361644744873\n",
      "2.313335657119751\n",
      "2.31330943107605\n",
      "2.313283920288086\n",
      "2.313258171081543\n",
      "2.313232898712158\n",
      "2.3132076263427734\n",
      "2.313182830810547\n",
      "2.3131582736968994\n",
      "2.31313419342041\n",
      "2.313110113143921\n",
      "2.3130860328674316\n",
      "2.313063144683838\n",
      "2.313039541244507\n",
      "2.313016414642334\n",
      "2.312993288040161\n",
      "2.3129706382751465\n",
      "2.312948226928711\n",
      "2.3129260540008545\n",
      "2.312903642654419\n",
      "2.3128821849823\n",
      "2.3128602504730225\n",
      "2.312838554382324\n",
      "2.3128175735473633\n",
      "2.3127963542938232\n",
      "2.3127756118774414\n",
      "2.3127551078796387\n",
      "2.312734603881836\n",
      "2.3127143383026123\n",
      "2.3126940727233887\n",
      "2.3126742839813232\n",
      "2.3126542568206787\n",
      "2.3126349449157715\n",
      "2.312615394592285\n",
      "2.312596321105957\n",
      "2.312577247619629\n",
      "2.312558174133301\n",
      "2.31253981590271\n",
      "2.312520980834961\n",
      "2.312502384185791\n",
      "2.3124842643737793\n",
      "2.312466621398926\n",
      "2.312448263168335\n",
      "2.3124308586120605\n",
      "2.312412977218628\n",
      "2.3123953342437744\n",
      "2.312378168106079\n",
      "2.312361001968384\n",
      "2.3123438358306885\n",
      "2.3123271465301514\n",
      "2.312310218811035\n",
      "2.312293767929077\n",
      "2.312277317047119\n",
      "2.312260627746582\n",
      "2.3122446537017822\n",
      "2.3122286796569824\n",
      "2.3122127056121826\n",
      "2.312196969985962\n",
      "2.3121814727783203\n",
      "2.3121659755706787\n",
      "2.312150716781616\n",
      "2.3121349811553955\n",
      "2.312119960784912\n",
      "2.312105178833008\n",
      "2.3120901584625244\n",
      "2.312074899673462\n",
      "2.312060594558716\n",
      "2.3120460510253906\n",
      "2.3120312690734863\n",
      "2.3120172023773193\n",
      "2.3120028972625732\n",
      "2.3119888305664062\n",
      "2.3119747638702393\n",
      "2.3119609355926514\n",
      "2.3119468688964844\n",
      "2.3119332790374756\n",
      "2.311919689178467\n",
      "2.311906337738037\n",
      "2.3118927478790283\n",
      "2.3118796348571777\n",
      "2.311866521835327\n",
      "2.3118531703948975\n",
      "2.311840295791626\n",
      "2.3118274211883545\n",
      "2.311814546585083\n",
      "2.3118019104003906\n",
      "2.3117892742156982\n",
      "2.311777114868164\n",
      "2.3117644786834717\n",
      "2.3117520809173584\n",
      "2.311739921569824\n",
      "2.31172776222229\n",
      "2.311715841293335\n",
      "2.311703681945801\n",
      "2.3116917610168457\n",
      "2.3116800785064697\n",
      "2.3116681575775146\n",
      "2.3116564750671387\n",
      "2.311645030975342\n",
      "2.311633348464966\n",
      "2.311622381210327\n",
      "2.3116109371185303\n",
      "2.3115997314453125\n",
      "2.3115882873535156\n",
      "2.311577320098877\n",
      "2.3115663528442383\n",
      "2.3115556240081787\n",
      "2.311544418334961\n",
      "2.3115336894989014\n",
      "2.311522960662842\n",
      "2.3115127086639404\n",
      "2.311501979827881\n",
      "2.3114917278289795\n",
      "2.31148099899292\n",
      "2.3114705085754395\n",
      "2.311460494995117\n",
      "2.311450242996216\n",
      "2.3114402294158936\n",
      "2.311429977416992\n",
      "2.31141996383667\n",
      "2.3114099502563477\n",
      "2.3113999366760254\n",
      "2.3113903999328613\n",
      "2.311380624771118\n",
      "2.311370849609375\n",
      "2.311361074447632\n",
      "2.311351776123047\n",
      "2.3113420009613037\n",
      "2.3113324642181396\n",
      "2.3113231658935547\n",
      "2.3113138675689697\n",
      "2.3113043308258057\n",
      "2.3112952709198\n",
      "2.311286211013794\n",
      "2.311277389526367\n",
      "2.3112683296203613\n",
      "2.3112592697143555\n",
      "2.3112499713897705\n",
      "2.311241388320923\n",
      "2.311232566833496\n",
      "2.3112239837646484\n",
      "2.3112149238586426\n",
      "2.311206102371216\n",
      "2.311197519302368\n",
      "2.3111891746520996\n",
      "2.311180830001831\n",
      "2.3111722469329834\n",
      "2.3111636638641357\n",
      "2.311155319213867\n",
      "2.3111472129821777\n",
      "2.311138868331909\n",
      "2.3111307621002197\n",
      "2.311122417449951\n",
      "2.311114549636841\n",
      "2.3111062049865723\n",
      "2.311098337173462\n",
      "2.3110902309417725\n",
      "2.311082363128662\n",
      "2.3110744953155518\n",
      "2.3110666275024414\n",
      "2.311058759689331\n",
      "2.3110511302948\n",
      "2.3110435009002686\n",
      "2.311035633087158\n",
      "2.311028003692627\n",
      "2.311020612716675\n",
      "2.3110127449035645\n",
      "2.3110053539276123\n",
      "2.31099796295166\n",
      "2.310990333557129\n",
      "2.310983180999756\n",
      "2.3109757900238037\n",
      "2.3109683990478516\n",
      "2.3109612464904785\n",
      "2.3109538555145264\n",
      "2.3109467029571533\n",
      "2.3109397888183594\n",
      "2.3109326362609863\n",
      "2.3109254837036133\n",
      "2.3109183311462402\n",
      "2.3109116554260254\n",
      "2.3109045028686523\n",
      "2.3108975887298584\n",
      "2.3108909130096436\n",
      "2.3108837604522705\n",
      "2.3108770847320557\n",
      "2.310870409011841\n",
      "2.310863494873047\n",
      "2.310857057571411\n",
      "2.3108503818511963\n",
      "2.3108437061309814\n",
      "2.3108367919921875\n",
      "2.3108303546905518\n",
      "2.310823917388916\n",
      "2.3108174800872803\n",
      "2.3108110427856445\n",
      "2.3108043670654297\n",
      "2.310798168182373\n",
      "2.3107917308807373\n",
      "2.3107852935791016\n",
      "2.310778856277466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3107728958129883\n",
      "2.3107664585113525\n",
      "2.310760259628296\n",
      "2.3107540607452393\n",
      "2.3107478618621826\n",
      "2.310742139816284\n",
      "2.3107357025146484\n",
      "2.310729742050171\n",
      "2.3107235431671143\n",
      "2.3107175827026367\n",
      "2.31071138381958\n",
      "2.3107054233551025\n",
      "2.310699701309204\n",
      "2.3106937408447266\n",
      "2.310688018798828\n",
      "2.3106820583343506\n",
      "2.310676336288452\n",
      "2.3106703758239746\n",
      "2.3106648921966553\n",
      "2.310659408569336\n",
      "2.3106529712677\n",
      "2.310647487640381\n",
      "2.3106417655944824\n",
      "2.310636520385742\n",
      "2.3106307983398438\n",
      "2.3106250762939453\n",
      "2.310619831085205\n",
      "2.3106138706207275\n",
      "2.310608148574829\n",
      "2.310603141784668\n",
      "2.3105976581573486\n",
      "2.31059193611145\n",
      "2.31058669090271\n",
      "2.3105812072753906\n",
      "2.3105759620666504\n",
      "2.31057071685791\n",
      "2.310565233230591\n",
      "2.3105599880218506\n",
      "2.3105545043945312\n",
      "2.31054949760437\n",
      "2.310544013977051\n",
      "2.3105390071868896\n",
      "2.3105337619781494\n",
      "2.310528516769409\n",
      "2.310523271560669\n",
      "2.310518264770508\n",
      "2.3105132579803467\n",
      "2.3105080127716064\n",
      "2.310502767562866\n",
      "2.310497999191284\n",
      "2.310492992401123\n",
      "2.310487747192383\n",
      "2.310482978820801\n",
      "2.3104779720306396\n",
      "2.3104732036590576\n",
      "2.3104684352874756\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    opt.zero_grad()\n",
    "    loss = dist(Z)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4458130acdae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TRAIN:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TEST:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
