{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "# import standard libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import gust\n",
    "\n",
    "# import embedding methods\n",
    "from embedding.bernoulli import Bernoulli\n",
    "\n",
    "# import utils\n",
    "from utils import graph_util\n",
    "\n",
    "# visualization\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "A, y = graph_util.load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Link prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train, validation and test data\n",
    "train_ones, val_ones, val_zeros, test_ones, test_zeros = gust.train_val_test_split_adjacency(A, p_val=0, p_test=0.05, random_state=0, neg_mul=1,\n",
    "                                   every_node=True, connected=False, undirected=True,\n",
    "                                   use_edge_cover=True, set_ops=True, asserts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9630, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2485, 2485)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2485, 2485)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct graph with train nodes only\n",
    "A_train_nodes = gust.edges_to_sparse(train_ones,A.shape[0])\n",
    "A_train_nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0, loss = 0.99128\n",
      "Epoch  250, loss = 0.01004\n",
      "Epoch  500, loss = 0.00405\n",
      "Epoch  750, loss = 0.00248\n",
      "Epoch 1000, loss = 0.00184\n",
      "Epoch 1250, loss = 0.00149\n",
      "Epoch 1500, loss = 0.00128\n",
      "Epoch 1750, loss = 0.00113\n",
      "Epoch 2000, loss = 0.00103\n",
      "Epoch 2250, loss = 0.00095\n",
      "Epoch 2500, loss = 0.00088\n",
      "Epoch 2750, loss = 0.00083\n",
      "Epoch 3000, loss = 0.00078\n",
      "Epoch 3250, loss = 0.00074\n",
      "Epoch 3500, loss = 0.00070\n",
      "Epoch 3750, loss = 0.00067\n",
      "Epoch 4000, loss = 0.00064\n",
      "Epoch 4250, loss = 0.00061\n",
      "Epoch 4500, loss = 0.00059\n",
      "Epoch 4750, loss = 0.00056\n"
     ]
    }
   ],
   "source": [
    "# learn Bernoulli baseline model\n",
    "b = Bernoulli(embedding_dimension=64, distance_meassure='sigmoid')\n",
    "emb = b.learn_embedding(A_train_nodes)\n",
    "\n",
    "np.save('ber_link_prediction_cora_embedding.npy',emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of adjacency matrix: (2485, 2485)\n",
      "Shape of embedding matrix: (2485, 64)\n"
     ]
    }
   ],
   "source": [
    "# load node embeddings\n",
    "emb = np.load('ber_link_prediction_cora_embedding.npy')\n",
    "\n",
    "print(f'Shape of adjacency matrix: {A_train_nodes.shape}')\n",
    "print(f'Shape of embedding matrix: {emb.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19260, 64)\n",
      "(19260,)\n",
      "(1016, 64)\n",
      "(1016,)\n"
     ]
    }
   ],
   "source": [
    "def create_edge_embedding(emb1, emb2, method=\"average\"):\n",
    "    if method==\"average\":\n",
    "        return (emb1+emb2)/2\n",
    "    \n",
    "train_zeros = []\n",
    "while len(train_zeros) < len(train_ones):\n",
    "    i, j = np.random.randint(0, emb.shape[0]-1, 2)\n",
    "    if A[i, j] == 0 and (i, j) not in train_zeros:\n",
    "        train_zeros.append((i, j))\n",
    "train_zeros = np.array(train_zeros)      \n",
    "\n",
    "# Create edge embeddings for train_ones, train_zeros, test_ones, test_zeros\n",
    "train_X = []\n",
    "train_y = []\n",
    "\n",
    "for nodes in train_ones:\n",
    "    node_emb1 = emb[nodes[0]]\n",
    "    node_emb2 = emb[nodes[1]]\n",
    "    edge_emb_one = create_edge_embedding(node_emb1, node_emb2, method=\"average\")\n",
    "    train_X.append(edge_emb_one)\n",
    "    train_y.append(1)\n",
    "\n",
    "for nodes in train_zeros:\n",
    "    node_emb1 = emb[nodes[0]]\n",
    "    node_emb2 = emb[nodes[1]]\n",
    "    edge_emb_one = create_edge_embedding(node_emb1, node_emb2, method=\"average\")\n",
    "    train_X.append(edge_emb_one)\n",
    "    train_y.append(0)\n",
    "\n",
    "    \n",
    "test_X = []\n",
    "test_y = []\n",
    "\n",
    "for nodes in test_ones:\n",
    "    node_emb1 = emb[nodes[0]]\n",
    "    node_emb2 = emb[nodes[1]]\n",
    "    edge_emb_one = create_edge_embedding(node_emb1, node_emb2, method=\"average\")\n",
    "    test_X.append(edge_emb_one)\n",
    "    test_y.append(1)\n",
    "    \n",
    "for nodes in test_zeros:\n",
    "    node_emb1 = emb[nodes[0]]\n",
    "    node_emb2 = emb[nodes[1]]\n",
    "    edge_emb_zero = create_edge_embedding(node_emb1, node_emb2, method=\"average\")\n",
    "    test_X.append(edge_emb_zero)\n",
    "    test_y.append(0)\n",
    "    \n",
    "    \n",
    "# Create train tuples (edge embedding, label) and test tuples (edge embedding, label)\n",
    "train_X = np.array(train_X)\n",
    "train_y = np.array(train_y)\n",
    "test_X = np.array(test_X)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Logistic Regression: 0.5787401574803149\n",
      "Accuracy Random Forest: 0.734251968503937\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression()\n",
    "lg.fit(train_X, train_y)\n",
    "score = lg.score(test_X, test_y)\n",
    "print(f'Accuracy Logistic Regression: {score}')\n",
    "\n",
    "\n",
    "# Train random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(train_X, train_y)\n",
    "score = rf.score(test_X, test_y)\n",
    "print(f'Accuracy Random Forest: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = lg.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57810178, 0.42189822],\n",
       "       [0.63118872, 0.36881128],\n",
       "       [0.47774985, 0.52225015],\n",
       "       ...,\n",
       "       [0.50045583, 0.49954417],\n",
       "       [0.52008864, 0.47991136],\n",
       "       [0.44684009, 0.55315991]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize(emb, y):\n",
    "#     emb = emb.cpu().detach().numpy()\n",
    "    tsne = TSNE()\n",
    "    vis = tsne.fit_transform(emb)\n",
    "    plt.figure(figsize=[10, 8])\n",
    "    plt.scatter(vis[:, 0], vis[:, 1], c=palette[y], s=20, alpha=0.8)\n",
    "    \n",
    "# Alternative to the default seaborn palette\n",
    "palette = np.array(sns.color_palette('muted', n_colors=len(np.unique(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(emb, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
